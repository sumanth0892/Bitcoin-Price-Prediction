{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import dataPrep as dP\n",
    "pd.set_option('display.width',200)\n",
    "pd.set_option('display.max_columns',200)\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4363457 entries, 0 to 4363456\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   Timestamp          int64  \n",
      " 1   Open               float64\n",
      " 2   High               float64\n",
      " 3   Low                float64\n",
      " 4   Close              float64\n",
      " 5   Volume_(BTC)       float64\n",
      " 6   Volume_(Currency)  float64\n",
      " 7   Weighted_Price     float64\n",
      "dtypes: float64(7), int64(1)\n",
      "memory usage: 266.3 MB\n",
      "None\n",
      "Timestamp                  0\n",
      "Open                 1236977\n",
      "High                 1236977\n",
      "Low                  1236977\n",
      "Close                1236977\n",
      "Volume_(BTC)         1236977\n",
      "Volume_(Currency)    1236977\n",
      "Weighted_Price       1236977\n",
      "Date                       0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2099760 entries, 0 to 2099759\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   Timestamp          int64  \n",
      " 1   Open               float64\n",
      " 2   High               float64\n",
      " 3   Low                float64\n",
      " 4   Close              float64\n",
      " 5   Volume_(BTC)       float64\n",
      " 6   Volume_(Currency)  float64\n",
      " 7   Weighted_Price     float64\n",
      "dtypes: float64(7), int64(1)\n",
      "memory usage: 128.2 MB\n",
      "None\n",
      "\n",
      "\n",
      "Timestamp                 0\n",
      "Open                 109069\n",
      "High                 109069\n",
      "Low                  109069\n",
      "Close                109069\n",
      "Volume_(BTC)         109069\n",
      "Volume_(Currency)    109069\n",
      "Weighted_Price       109069\n",
      "Date                      0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1990691 entries, 0 to 1990690\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   Timestamp          int64  \n",
      " 1   Open               float64\n",
      " 2   High               float64\n",
      " 3   Low                float64\n",
      " 4   Close              float64\n",
      " 5   Volume_(BTC)       float64\n",
      " 6   Volume_(Currency)  float64\n",
      " 7   Weighted_Price     float64\n",
      " 8   Date               object \n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 151.9+ MB\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Get the bitstamp and the coinbase data \n",
    "bitstampData = dP.getBitstampData()\n",
    "coinbaseData = dP.coinbaseData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have data from two sources for bitcoin prices - One from Bitstamp and the other from Coinbase. It is given as Time Series and let's look at the tasks which can be performed using Time Series Analysis (ARIMA, RNN and LSTM). \n",
    "Start by extracting the relevant data:\n",
    "Date as the Index \n",
    "Weighted Price at different points in time \n",
    "Amount of Bitcoin transacted in the time window\n",
    "Volume of currency transacted in the time window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To construct the time series for analysis, let's choose one value from each day. The most obvious way to do this is to go with the last recorded time and make it as a proxy for the entire day. This works somewhat for prices, but not so much for the Volume of currency or the weighted price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3033 entries, 2011-12-31 to 2020-04-22\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Open               3033 non-null   float64\n",
      " 1   High               3033 non-null   float64\n",
      " 2   Low                3033 non-null   float64\n",
      " 3   Close              3033 non-null   float64\n",
      " 4   Volume_(BTC)       3033 non-null   float64\n",
      " 5   Volume_(Currency)  3033 non-null   float64\n",
      " 6   Weighted_Price     3033 non-null   float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 189.6+ KB\n",
      "None\n",
      "                Open      High       Low     Close  Volume_(BTC)  Volume_(Currency)  Weighted_Price\n",
      "Date                                                                                               \n",
      "2011-12-31  4.465000  4.482500  4.465000  4.482500     23.829470         106.330084        4.471603\n",
      "2012-01-01  4.806667  4.806667  4.806667  4.806667      7.200667          35.259720        4.806667\n",
      "2012-01-02  5.000000  5.000000  5.000000  5.000000     19.048000          95.240000        5.000000\n",
      "2012-01-03  5.252500  5.252500  5.252500  5.252500     11.004660          58.100651        5.252500\n",
      "2012-01-04  5.200000  5.223333  5.200000  5.223333     11.914807          63.119577        5.208159\n",
      "2012-01-05  6.281429  6.286190  6.281429  6.286190      4.514373          27.987370        6.284127\n",
      "2012-01-06  6.435000  6.445000  6.435000  6.445000      2.420196          15.914659        6.438999\n",
      "2012-01-07  6.800000  6.800000  6.800000  6.800000      0.295858           2.011834        6.800000\n",
      "2012-01-08  6.950000  6.950000  6.950000  6.950000      2.500000          17.300000        6.950000\n",
      "2012-01-09  6.584167  6.584167  6.581667  6.581667      1.857481          12.306798        6.582770\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3033 entries, 2011-12-31 to 2020-04-22\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Open               3033 non-null   float64\n",
      " 1   High               3033 non-null   float64\n",
      " 2   Low                3033 non-null   float64\n",
      " 3   Close              3033 non-null   float64\n",
      " 4   Volume_(BTC)       3033 non-null   float64\n",
      " 5   Volume_(Currency)  3033 non-null   float64\n",
      " 6   Weighted_Price     3033 non-null   float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 189.6+ KB\n",
      "None\n",
      "            Open  High   Low  Close  Volume_(BTC)  Volume_(Currency)  Weighted_Price\n",
      "Date                                                                                \n",
      "2011-12-31  4.58  4.58  4.58   4.58     48.000000         210.720000        4.580000\n",
      "2012-01-01  5.00  5.00  5.00   5.00     10.100000          50.500000        5.000000\n",
      "2012-01-02  5.00  5.00  5.00   5.00     19.048000          95.240000        5.000000\n",
      "2012-01-03  5.32  5.32  5.32   5.32     29.319392         155.010000        5.320000\n",
      "2012-01-04  5.37  5.57  5.37   5.57     43.312196         235.747069        5.442972\n",
      "2012-01-05  6.65  6.65  6.65   6.65     20.777444         138.170000        6.650000\n",
      "2012-01-06  6.80  6.90  6.80   6.90      9.310559          63.611801        6.832221\n",
      "2012-01-07  6.80  6.80  6.80   6.80      0.295858           2.011834        6.800000\n",
      "2012-01-08  7.00  7.00  7.00   7.00      4.000000          27.600000        7.000000\n",
      "2012-01-09  6.99  6.99  6.90   6.90     13.600000          88.400000        6.939708\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1465 entries, 2014-12-01 to 2019-01-07\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Open               1465 non-null   float64\n",
      " 1   High               1465 non-null   float64\n",
      " 2   Low                1465 non-null   float64\n",
      " 3   Close              1465 non-null   float64\n",
      " 4   Volume_(BTC)       1465 non-null   float64\n",
      " 5   Volume_(Currency)  1465 non-null   float64\n",
      " 6   Weighted_Price     1465 non-null   float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 91.6+ KB\n",
      "None\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1465 entries, 2014-12-01 to 2019-01-07\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Open               1465 non-null   float64\n",
      " 1   High               1465 non-null   float64\n",
      " 2   Low                1465 non-null   float64\n",
      " 3   Close              1465 non-null   float64\n",
      " 4   Volume_(BTC)       1465 non-null   float64\n",
      " 5   Volume_(Currency)  1465 non-null   float64\n",
      " 6   Weighted_Price     1465 non-null   float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 91.6+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ngroup = bitstampData.groupby('Date')\\nmeanValues = group.mean()\\nmaxValues = group.max()\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Group by date and extract the maximum and the mean values\n",
    "def getMeanAndMaxValues(df):\n",
    "    df = df.groupby('Date')\n",
    "    meanValues = df.mean()\n",
    "    maxValues = df.max()\n",
    "    return meanValues,maxValues\n",
    "muBitstamp,maxBitstamp = getMeanAndMaxValues(bitstampData)\n",
    "muCoinbase,maxCoinbase = getMeanAndMaxValues(coinbaseData)\n",
    "#Free up some memory \n",
    "del bitstampData,coinbaseData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2933, 1)\n",
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "#Let's predict using the data from Bitstamp exchange since more points are available here\n",
    "#Than the data from Coinbase\n",
    "#Use the weighted prices and the closing prices.\n",
    "import numpy as np\n",
    "meanWeightedPrices = muBitstamp['Weighted_Price']\n",
    "maxWeightedPrices = maxBitstamp['Weighted_Price']\n",
    "meanClosingPrices = muBitstamp['Close']\n",
    "maxClosingPrices = maxBitstamp['Close']\n",
    "#Split into training and test data \n",
    "#I choose last 100 rows as testing data \n",
    "weightedTrainMean = meanWeightedPrices.iloc[:len(meanWeightedPrices) - 100]\n",
    "weightedTestMean = meanWeightedPrices.iloc[len(weightedTrainMean):]\n",
    "weightedTrainMax = maxWeightedPrices.iloc[:len(maxWeightedPrices) - 100]\n",
    "weightedTestMax = maxWeightedPrices.iloc[len(weightedTrainMax):]\n",
    "weightedTrainMean = np.array(weightedTrainMean)\n",
    "weightedTestMean = np.array(weightedTestMean)\n",
    "weightedTrainMean = np.reshape(weightedTrainMean,(len(weightedTrainMean),1))\n",
    "weightedTestMean = np.reshape(weightedTestMean,(len(weightedTestMean),1))\n",
    "#print(weightedTrainMean.shape)\n",
    "#print(weightedTestMean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2833, 100, 1)\n",
      "(2833,)\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing step 2: Scale the values between 0 and 1 using scikit library\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def getTrainingData(X,timeStep):\n",
    "    #X is the Time series in the form of an array and timeStep is the chosen timestep\n",
    "    #Returns a training array and a set of labels matching the shape\n",
    "    scaler=MinMaxScaler(feature_range=(0,1))\n",
    "    X = scaler.fit_transform(X)\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for i in range(timeStep,X.shape[0]):\n",
    "        x_train.append(X[i-timeStep:i,0])\n",
    "        y_train.append(X[i,0])\n",
    "    return np.array(x_train),np.array(y_train)\n",
    "X_weightedPrice_mean,Y_weightedPrice_mean = getTrainingData(weightedTrainMean,100)\n",
    "X_weightedPrice_mean = np.reshape(X_weightedPrice_mean,(X_weightedPrice_mean.shape[0],X_weightedPrice_mean.shape[1],1))\n",
    "print(X_weightedPrice_mean.shape)\n",
    "print(Y_weightedPrice_mean.shape)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 100, 128)          16640     \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 100, 64)           12352     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 64)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 100, 64)           8256      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 6401      \n",
      "=================================================================\n",
      "Total params: 43,649\n",
      "Trainable params: 43,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "2833/2833 [==============================] - 6s 2ms/step - loss: 0.0062\n",
      "Epoch 2/100\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 0.0020\n",
      "Epoch 3/100\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 0.0018\n",
      "Epoch 4/100\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 0.0014\n",
      "Epoch 5/100\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 0.0011\n",
      "Epoch 6/100\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 9.6293e-04\n",
      "Epoch 7/100\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 9.7389e-04\n",
      "Epoch 8/100\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 8.3173e-04\n",
      "Epoch 9/100\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 6.7632e-04\n",
      "Epoch 10/100\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 6.8477e-04\n",
      "Epoch 11/100\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 8.2394e-04\n",
      "Epoch 12/100\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 6.1006e-04\n",
      "Epoch 13/100\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 8.2173e-04\n",
      "Epoch 14/100\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 6.8336e-04\n",
      "Epoch 15/100\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 5.1623e-04\n",
      "Epoch 16/100\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 5.9013e-04\n",
      "Epoch 17/100\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 5.1042e-04\n",
      "Epoch 18/100\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 4.9732e-04\n",
      "Epoch 19/100\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 5.0757e-04\n",
      "Epoch 20/100\n",
      "2496/2833 [=========================>....] - ETA: 0s - loss: 4.2587e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-a2727f27272a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_weightedPrice_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_weightedPrice_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Build and compile the RNN\n",
    "_,m,n = X_weightedPrice_mean.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, Dropout,Flatten\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(128,activation = 'relu',return_sequences = True,input_shape = (m,n)))\n",
    "model.add(SimpleRNN(64,activation = 'relu',return_sequences = True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(SimpleRNN(64,activation = 'relu',return_sequences = True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_squared_error',optimizer = 'adam',metrics - ['accuracy'])\n",
    "model.summary()\n",
    "history = model.fit(X_weightedPrice_mean,Y_weightedPrice_mean,epochs = 100,batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-29f4f89aad87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "history.history \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
