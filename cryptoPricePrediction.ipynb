{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import dataPrep as dP\n",
    "pd.set_option('display.width',200)\n",
    "pd.set_option('display.max_columns',200)\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4363457 entries, 0 to 4363456\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   Timestamp          int64  \n",
      " 1   Open               float64\n",
      " 2   High               float64\n",
      " 3   Low                float64\n",
      " 4   Close              float64\n",
      " 5   Volume_(BTC)       float64\n",
      " 6   Volume_(Currency)  float64\n",
      " 7   Weighted_Price     float64\n",
      "dtypes: float64(7), int64(1)\n",
      "memory usage: 266.3 MB\n",
      "None\n",
      "Timestamp                  0\n",
      "Open                 1236977\n",
      "High                 1236977\n",
      "Low                  1236977\n",
      "Close                1236977\n",
      "Volume_(BTC)         1236977\n",
      "Volume_(Currency)    1236977\n",
      "Weighted_Price       1236977\n",
      "Date                       0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2099760 entries, 0 to 2099759\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   Timestamp          int64  \n",
      " 1   Open               float64\n",
      " 2   High               float64\n",
      " 3   Low                float64\n",
      " 4   Close              float64\n",
      " 5   Volume_(BTC)       float64\n",
      " 6   Volume_(Currency)  float64\n",
      " 7   Weighted_Price     float64\n",
      "dtypes: float64(7), int64(1)\n",
      "memory usage: 128.2 MB\n",
      "None\n",
      "\n",
      "\n",
      "Timestamp                 0\n",
      "Open                 109069\n",
      "High                 109069\n",
      "Low                  109069\n",
      "Close                109069\n",
      "Volume_(BTC)         109069\n",
      "Volume_(Currency)    109069\n",
      "Weighted_Price       109069\n",
      "Date                      0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1990691 entries, 0 to 1990690\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   Timestamp          int64  \n",
      " 1   Open               float64\n",
      " 2   High               float64\n",
      " 3   Low                float64\n",
      " 4   Close              float64\n",
      " 5   Volume_(BTC)       float64\n",
      " 6   Volume_(Currency)  float64\n",
      " 7   Weighted_Price     float64\n",
      " 8   Date               object \n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 151.9+ MB\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Get the bitstamp and the coinbase data \n",
    "bitstampData = dP.getBitstampData()\n",
    "coinbaseData = dP.coinbaseData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have data from two sources for bitcoin prices - One from Bitstamp and the other from Coinbase. It is given as Time Series and let's look at the tasks which can be performed using Time Series Analysis (ARIMA, RNN and LSTM). \n",
    "Start by extracting the relevant data:\n",
    "Date as the Index \n",
    "Weighted Price at different points in time \n",
    "Amount of Bitcoin transacted in the time window\n",
    "Volume of currency transacted in the time window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To construct the time series for analysis, let's choose one value from each day. The most obvious way to do this is to go with the last recorded time and make it as a proxy for the entire day. This works somewhat for prices, but not so much for the Volume of currency or the weighted price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group by date and extract the maximum and the mean values\n",
    "def getMeanAndMaxValues(df):\n",
    "    df = df.groupby('Date')\n",
    "    meanValues = df.mean()\n",
    "    maxValues = df.max()\n",
    "    return meanValues,maxValues\n",
    "muBitstamp,maxBitstamp = getMeanAndMaxValues(bitstampData)\n",
    "muCoinbase,maxCoinbase = getMeanAndMaxValues(coinbaseData)\n",
    "#Free up some memory \n",
    "del bitstampData,coinbaseData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's predict using the data from Bitstamp exchange since more points are available here\n",
    "#Than the data from Coinbase\n",
    "#Use the weighted prices and the closing prices.\n",
    "import numpy as np\n",
    "meanWeightedPrices = muBitstamp['Weighted_Price']\n",
    "maxWeightedPrices = maxBitstamp['Weighted_Price']\n",
    "meanClosingPrices = muBitstamp['Close']\n",
    "maxClosingPrices = maxBitstamp['Close']\n",
    "#Split into training and test data \n",
    "#I choose last 100 rows as testing data \n",
    "weightedTrainMean = meanWeightedPrices.iloc[:len(meanWeightedPrices) - 100]\n",
    "weightedTestMean = meanWeightedPrices.iloc[len(weightedTrainMean):]\n",
    "weightedTrainMax = maxWeightedPrices.iloc[:len(maxWeightedPrices) - 100]\n",
    "weightedTestMax = maxWeightedPrices.iloc[len(weightedTrainMax):]\n",
    "weightedTrainMean = np.array(weightedTrainMean)\n",
    "weightedTestMean = np.array(weightedTestMean)\n",
    "weightedTrainMean = np.reshape(weightedTrainMean,(len(weightedTrainMean),1))\n",
    "weightedTestMean = np.reshape(weightedTestMean,(len(weightedTestMean),1))\n",
    "#print(weightedTrainMean.shape)\n",
    "#print(weightedTestMean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2833, 100, 1)\n",
      "(2833,)\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing step 2: Scale the values between 0 and 1 using scikit library\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def getTrainingData(X,timeStep):\n",
    "    #X is the Time series in the form of an array and timeStep is the chosen timestep\n",
    "    #Returns a training array and a set of labels matching the shape\n",
    "    scaler=MinMaxScaler(feature_range=(0,1))\n",
    "    X = scaler.fit_transform(X)\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for i in range(timeStep,X.shape[0]):\n",
    "        x_train.append(X[i-timeStep:i,0])\n",
    "        y_train.append(X[i,0])\n",
    "    return np.array(x_train),np.array(y_train)\n",
    "X_weightedPrice_mean,Y_weightedPrice_mean = getTrainingData(weightedTrainMean,100)\n",
    "X_weightedPrice_mean = np.reshape(X_weightedPrice_mean,(X_weightedPrice_mean.shape[0],X_weightedPrice_mean.shape[1],1))\n",
    "print(X_weightedPrice_mean.shape)\n",
    "print(Y_weightedPrice_mean.shape)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 100, 128)          16640     \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 100, 64)           12352     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 64)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 100, 64)           8256      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 6401      \n",
      "=================================================================\n",
      "Total params: 43,649\n",
      "Trainable params: 43,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "2833/2833 [==============================] - 6s 2ms/step - loss: 0.0048\n",
      "Epoch 2/50\n",
      "2833/2833 [==============================] - 6s 2ms/step - loss: 0.0021\n",
      "Epoch 3/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 0.0014\n",
      "Epoch 4/50\n",
      "2833/2833 [==============================] - 6s 2ms/step - loss: 0.0013\n",
      "Epoch 5/50\n",
      "2833/2833 [==============================] - 6s 2ms/step - loss: 8.8695e-04\n",
      "Epoch 6/50\n",
      "2833/2833 [==============================] - 7s 2ms/step - loss: 9.3477e-04\n",
      "Epoch 7/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 8.1521e-04\n",
      "Epoch 8/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 6.9406e-04\n",
      "Epoch 9/50\n",
      "2833/2833 [==============================] - 7s 2ms/step - loss: 7.2149e-04\n",
      "Epoch 10/50\n",
      "2833/2833 [==============================] - 7s 2ms/step - loss: 5.8346e-04\n",
      "Epoch 11/50\n",
      "2833/2833 [==============================] - 7s 3ms/step - loss: 6.3759e-04\n",
      "Epoch 12/50\n",
      "2833/2833 [==============================] - 6s 2ms/step - loss: 6.4707e-04\n",
      "Epoch 13/50\n",
      "2833/2833 [==============================] - 6s 2ms/step - loss: 4.9493e-04\n",
      "Epoch 14/50\n",
      "2833/2833 [==============================] - 7s 3ms/step - loss: 4.7110e-04\n",
      "Epoch 15/50\n",
      "2833/2833 [==============================] - 7s 3ms/step - loss: 5.9137e-04\n",
      "Epoch 16/50\n",
      "2833/2833 [==============================] - 6s 2ms/step - loss: 3.8062e-04\n",
      "Epoch 17/50\n",
      "2833/2833 [==============================] - 6s 2ms/step - loss: 4.6865e-04\n",
      "Epoch 18/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 4.2225e-04\n",
      "Epoch 19/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 4.5320e-04\n",
      "Epoch 20/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 4.2169e-04\n",
      "Epoch 21/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 4.1725e-04\n",
      "Epoch 22/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 3.8348e-04\n",
      "Epoch 23/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 4.9737e-04\n",
      "Epoch 24/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 4.9116e-04\n",
      "Epoch 25/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 4.1395e-04\n",
      "Epoch 26/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 4.2430e-04\n",
      "Epoch 27/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 5.1810e-04\n",
      "Epoch 28/50\n",
      "2833/2833 [==============================] - 6s 2ms/step - loss: 4.3497e-04\n",
      "Epoch 29/50\n",
      "2833/2833 [==============================] - 6s 2ms/step - loss: 4.8514e-04\n",
      "Epoch 30/50\n",
      "2833/2833 [==============================] - 6s 2ms/step - loss: 4.3969e-04\n",
      "Epoch 31/50\n",
      "2833/2833 [==============================] - 7s 2ms/step - loss: 4.6293e-04\n",
      "Epoch 32/50\n",
      "2833/2833 [==============================] - 6s 2ms/step - loss: 4.0809e-04\n",
      "Epoch 33/50\n",
      "2833/2833 [==============================] - 6s 2ms/step - loss: 3.2148e-04\n",
      "Epoch 34/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 3.3688e-04\n",
      "Epoch 35/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 3.2024e-04\n",
      "Epoch 36/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 4.5055e-04\n",
      "Epoch 37/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 2.9762e-04\n",
      "Epoch 38/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 3.5805e-04\n",
      "Epoch 39/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 2.9790e-04\n",
      "Epoch 40/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 3.1679e-04\n",
      "Epoch 41/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 2.8958e-04\n",
      "Epoch 42/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 2.5902e-04\n",
      "Epoch 43/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 3.2121e-04\n",
      "Epoch 44/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 2.4823e-04\n",
      "Epoch 45/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 3.1942e-04\n",
      "Epoch 46/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 2.6872e-04\n",
      "Epoch 47/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 2.7552e-04\n",
      "Epoch 48/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 2.3869e-04\n",
      "Epoch 49/50\n",
      "2833/2833 [==============================] - 5s 2ms/step - loss: 2.9539e-04\n",
      "Epoch 50/50\n",
      "2833/2833 [==============================] - 6s 2ms/step - loss: 2.1377e-04\n"
     ]
    }
   ],
   "source": [
    "#Build and compile the RNN\n",
    "_,m,n = X_weightedPrice_mean.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, Dropout,Flatten\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(128,activation = 'relu',return_sequences = True,input_shape = (m,n)))\n",
    "model.add(SimpleRNN(64,activation = 'relu',return_sequences = True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(SimpleRNN(64,activation = 'relu',return_sequences = True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_squared_error',optimizer = 'adam')\n",
    "model.summary()\n",
    "history = model.fit(X_weightedPrice_mean,Y_weightedPrice_mean,epochs = 50,batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss'])\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "#Look at the keys in the dictionary\n",
    "print(history.history.keys())\n",
    "lossRNN = history.history['loss']\n",
    "print(len(lossRNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2833/2833 [==============================] - 4s 1ms/step - loss: 0.0248\n",
      "Epoch 2/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 6.7625e-04\n",
      "Epoch 3/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 4.9865e-04\n",
      "Epoch 4/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 4.5968e-04\n",
      "Epoch 5/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 4.2184e-04\n",
      "Epoch 6/50\n",
      "2833/2833 [==============================] - 4s 1ms/step - loss: 4.2210e-04\n",
      "Epoch 7/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 4.3600e-04\n",
      "Epoch 8/50\n",
      "2833/2833 [==============================] - 4s 1ms/step - loss: 3.9393e-04\n",
      "Epoch 9/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 3.9046e-04\n",
      "Epoch 10/50\n",
      "2833/2833 [==============================] - 4s 1ms/step - loss: 3.7771e-04\n",
      "Epoch 11/50\n",
      "2833/2833 [==============================] - 4s 1ms/step - loss: 3.4696e-04\n",
      "Epoch 12/50\n",
      "2833/2833 [==============================] - 4s 1ms/step - loss: 3.4496e-04\n",
      "Epoch 13/50\n",
      "2833/2833 [==============================] - 4s 2ms/step - loss: 3.4404e-04\n",
      "Epoch 14/50\n",
      "2833/2833 [==============================] - 4s 1ms/step - loss: 3.3608e-04\n",
      "Epoch 15/50\n",
      "2833/2833 [==============================] - 4s 1ms/step - loss: 3.2043e-04\n",
      "Epoch 16/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 3.1370e-04\n",
      "Epoch 17/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 2.9989e-04\n",
      "Epoch 18/50\n",
      "2833/2833 [==============================] - 3s 981us/step - loss: 2.9319e-04\n",
      "Epoch 19/50\n",
      "2833/2833 [==============================] - 3s 895us/step - loss: 3.0068e-04\n",
      "Epoch 20/50\n",
      "2833/2833 [==============================] - 3s 898us/step - loss: 2.8257e-04\n",
      "Epoch 21/50\n",
      "2833/2833 [==============================] - 3s 883us/step - loss: 2.6558e-04\n",
      "Epoch 22/50\n",
      "2833/2833 [==============================] - 3s 903us/step - loss: 2.7131e-04\n",
      "Epoch 23/50\n",
      "2833/2833 [==============================] - 3s 891us/step - loss: 2.5820e-04\n",
      "Epoch 24/50\n",
      "2833/2833 [==============================] - 3s 891us/step - loss: 2.5008e-04\n",
      "Epoch 25/50\n",
      "2833/2833 [==============================] - 3s 951us/step - loss: 2.3931e-04\n",
      "Epoch 26/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 2.3975e-04\n",
      "Epoch 27/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 2.3742e-04\n",
      "Epoch 28/50\n",
      "2833/2833 [==============================] - 3s 913us/step - loss: 2.5902e-04\n",
      "Epoch 29/50\n",
      "2833/2833 [==============================] - 3s 913us/step - loss: 2.2382e-04\n",
      "Epoch 30/50\n",
      "2833/2833 [==============================] - 3s 939us/step - loss: 2.2187e-04\n",
      "Epoch 31/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 2.1921e-04\n",
      "Epoch 32/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 2.0592e-04\n",
      "Epoch 33/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 2.0697e-04\n",
      "Epoch 34/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 2.1085e-04\n",
      "Epoch 35/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 2.1451e-04\n",
      "Epoch 36/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 2.1710e-04\n",
      "Epoch 37/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 2.1903e-04\n",
      "Epoch 38/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 2.0020e-04\n",
      "Epoch 39/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 2.0718e-04\n",
      "Epoch 40/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 1.9955e-04\n",
      "Epoch 41/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 1.9545e-04\n",
      "Epoch 42/50\n",
      "2833/2833 [==============================] - 4s 1ms/step - loss: 1.9410e-04\n",
      "Epoch 43/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 1.8940e-04\n",
      "Epoch 44/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 2.0333e-04\n",
      "Epoch 45/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 1.8386e-04\n",
      "Epoch 46/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 1.8071e-04\n",
      "Epoch 47/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 1.8133e-04\n",
      "Epoch 48/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 1.7959e-04\n",
      "Epoch 49/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 1.6934e-04\n",
      "Epoch 50/50\n",
      "2833/2833 [==============================] - 3s 1ms/step - loss: 1.7014e-04\n"
     ]
    }
   ],
   "source": [
    "#Build an LSTM model to predict prices. \n",
    "from keras.layers import LSTM,Dense \n",
    "from keras.models import Sequential\n",
    "modelLSTM = Sequential()\n",
    "modelLSTM.add(LSTM(20,input_shape = (None,1),activation = 'relu'))\n",
    "modelLSTM.add(Dense(1))\n",
    "modelLSTM.compile(loss = 'mean_squared_error',optimizer = 'adam')\n",
    "history = modelLSTM.fit(X_weightedPrice_mean,Y_weightedPrice_mean,epochs = 50,batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss'])\n",
      "The maximum loss in an RNN network is 0.0002137719811609477\n",
      "The maximum loss in an LSTM network is 0.00016934102982864673\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "lossLSTM = history.history['loss']\n",
    "print(\"The maximum loss in an RNN network is {}\".format(min(lossRNN)))\n",
    "print(\"The maximum loss in an LSTM network is {}\".format(min(lossLSTM)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
